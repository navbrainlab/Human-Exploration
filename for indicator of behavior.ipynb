{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import re\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib as mpl\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import mannwhitneyu\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些需要单独运行的函数：\n",
    "cal_attended_index() (分别用于四维的和三维的数据，有两个)\n",
    "food_preference_arr()\n",
    "get_dim_variance()\n",
    "plot_3d_trace()\n",
    "plot_3d_trace_score()\n",
    "dim_probed()\n",
    "probe_segments_length()\n",
    "dim_probe_counts()\n",
    "probe_sequence（）\n",
    "probe_fraction（）\n",
    "stick_fraction（）\n",
    "stick_sequence（）\n",
    "extract_key_From_filename（）\n",
    "get_round_behavour（）\n",
    "is_testing_trial（）\n",
    "get_stick_trial（）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for p2 p2only (12个食物)\n",
    "def cal_attended_index(round):\n",
    "    # a1 = 0, a2 = 0, a3 = 0\n",
    "    # b1 = 0, b2 = 0, b3 = 0\n",
    "    # c1 = 0, c2 = 0, c3 = 0\n",
    "    # d1 = 0, d2 = 0, d3 = 0\n",
    "    block1_list = [0]*12\n",
    "    block2_list = [0]*12\n",
    "    block3_list = [0]*12\n",
    "    \n",
    "    for choice in round[0]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block1_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block1_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block1_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    for choice in round[1]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block2_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block2_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block2_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    for choice in round[2]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block3_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block3_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block3_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    weights = [27,15,3]\n",
    "    food_arr = np.array([block1_list,block2_list,block3_list])\n",
    "    food_index = np.dot(weights, food_arr)\n",
    "    return food_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for p1 (9个食物) (跑p1数据前要重跑这个函数)\n",
    "def cal_attended_index(round):\n",
    "    block1_list = [0]*9\n",
    "    block2_list = [0]*9\n",
    "    block3_list = [0]*9\n",
    "    \n",
    "    for choice in round[0]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block1_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block1_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block1_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    for choice in round[1]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block2_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block2_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block2_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    for choice in round[2]:\n",
    "        choice_str = str(choice)\n",
    "        i = 0\n",
    "        for i in range(len(choice_str)):\n",
    "            if choice_str[i] == '1':\n",
    "                block3_list[0+i*3] +=1\n",
    "            if choice_str[i] == '2' :\n",
    "                block3_list[1+i*3] +=1\n",
    "            if choice_str[i] == '3':\n",
    "                block3_list[2+i*3] +=1\n",
    "            i+=1\n",
    "    weights = [27,9,3]\n",
    "    food_arr = np.array([block1_list,block2_list,block3_list])\n",
    "    food_index = np.dot(weights, food_arr)\n",
    "    return food_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_preference_arr(choice_sequence):\n",
    "    food_index_arr_list = []\n",
    "    data_int = choice_sequence.astype(int)\n",
    "    for round_idx, round in enumerate(data_int):\n",
    "        food_index_arr_list.append(cal_attended_index(round))\n",
    "    food_index_arr = np.array(food_index_arr_list)\n",
    "    return food_index_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义从food index计算dim variance的函数：----- for p1  \n",
    "def get_dim_variance(food_index_array):\n",
    "    #输入是每个被试的food_index序列on trial course (n * 12)\n",
    "    #输出应该是每个被试的dim_variance序列on trial course (n * 4 )\n",
    "    variance_list = []\n",
    "    for round in food_index_array:\n",
    "        variances = [np.var(round[i:i+3]) for i in range(0, len(round), 3)]\n",
    "        variance_list.append(variances)\n",
    "    variance_sequence_arr = np.array(variance_list)\n",
    "    #进行归一化：\n",
    "    min_values = variance_sequence_arr.min()\n",
    "    max_values = variance_sequence_arr.max()\n",
    "    normalized_var_seq_arr = (variance_sequence_arr - min_values) / (max_values - min_values)\n",
    "    return normalized_var_seq_arr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义3D可视化的函数：(on trial course)\n",
    "def plot_3d_trace(df, array_column_name, subject_column_name,score_column_name, save_dir):\n",
    "    import os\n",
    "    from matplotlib.lines import Line2D\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # 获取Subject值和对应的数组\n",
    "        subject_value = row[subject_column_name]\n",
    "        array_data = row[array_column_name]\n",
    "        score_value = np.max(row[score_column_name])\n",
    "\n",
    "        # 创建一个3D图形\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d') #降维到3维时改为3，降维到2维时改为2\n",
    "\n",
    "        for i in range(len(array_data)):\n",
    "            # 计算前后两个点之间的距离，如果距离较远，则使用不同的颜色\n",
    "            color_value = ( i / len(array_data))  # 归一化时间索引\n",
    "            if i == 0:\n",
    "                ax.plot(array_data[i, 0], array_data[i, 1],array_data[i, 2], 'bo', markersize=13, label='Start Point') #\n",
    "            elif i == len(array_data)-1:\n",
    "                ax.plot(array_data[i, 0], array_data[i, 1],array_data[i, 2], color='orange', marker='o', markersize=13, label='End Point')\n",
    "                # 绘制最后一段线\n",
    "                ax.plot([array_data[i-1, 0], array_data[i, 0]],\n",
    "                        [array_data[i-1, 1], array_data[i, 1]],\n",
    "                        [array_data[i-1, 2], array_data[i, 2]],\n",
    "                        color=plt.cm.viridis(color_value), marker='o')\n",
    "            else:\n",
    "                ax.plot([array_data[i-1, 0], array_data[i, 0]], [array_data[i-1, 1], array_data[i, 1]], \n",
    "                        [array_data[i-1, 2], array_data[i, 2]],\n",
    "                    color=plt.cm.viridis(color_value), marker='o')  # 使用RdPu颜色映射\n",
    "        \n",
    "        # 添加第一个黑色虚线圆圈\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)  # 圆的角度\n",
    "        r = 0.025  # 圆的半径\n",
    "        x_circle = 0.41025641 + r * np.cos(theta)\n",
    "        y_circle = 0.41025641 + r * np.sin(theta)\n",
    "        z_circle = np.full_like(theta, 0.17948718)  # 固定高度\n",
    "        ax.plot(x_circle, y_circle, z_circle, 'k--')  # 黑色虚线圆圈\n",
    "\n",
    "        # 自定义图例标记为黑色圆圈\n",
    "        circle_legend = Line2D([0], [0], marker='o', color='k', label='Full score point',\n",
    "                       markerfacecolor='w', markersize=10, linestyle='--')\n",
    "        start_point_legend = Line2D([0], [0], marker='o', color='blue', label='Start Point', markersize=12)\n",
    "        end_point_legend = Line2D([0], [0], marker='o', color='orange', label='End Point', markersize=12)\n",
    "\n",
    "        # 添加图例\n",
    "        ax.legend(handles=[start_point_legend,end_point_legend, circle_legend])\n",
    "\n",
    "        # 添加第二个黑色虚线圆圈\n",
    "        z_circle2 = np.full_like(theta, 0.0)  # 固定高度\n",
    "        ax.plot(x_circle, y_circle, z_circle2, 'k--')  \n",
    "\n",
    "\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_zlim(0, 1)        \n",
    "\n",
    "        # 颜色归一化\n",
    "        norm = Normalize(vmin=0, vmax=len(array_data) - 1)\n",
    "        # 颜色映射\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        cmap = ScalarMappable(norm=norm, cmap=cmap)\n",
    "        # 添加颜色条\n",
    "        fig.colorbar(cmap, ax=ax, label='Round number')\n",
    "        # 设置标签\n",
    "        ax.set_xlabel('Relevant dimension 1', fontsize = 19)\n",
    "        ax.set_ylabel('Relevant dimension 2', fontsize = 19)\n",
    "        ax.set_zlabel('Non-relevant dimension', fontsize = 19)\n",
    "        # ax.text(0.1,0.99, f'Highest score: {score_value}',fontsize = 18, color = 'crimson', ha='left', va='top',transform=ax.transAxes )\n",
    "        # 设置标题\n",
    "        ax.set_title(f'Exploration trace for {subject_value} highest score {score_value}.png')\n",
    "        image_filename = os.path.join(save_dir, f'Exploration trace for {subject_value} highest score {score_value}.png')\n",
    "        plt.savefig(image_filename)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义3D可视化的函数：(with score)\n",
    "def plot_3d_trace_score(df, array_column_name, subject_column_name, score_column_name, save_dir):\n",
    "    import os\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # 获取Subject值和对应的数组\n",
    "        subject_value = row[subject_column_name]\n",
    "        array_data = row[array_column_name]\n",
    "        score_value = row[score_column_name]\n",
    "\n",
    "        # 创建一个3D图形\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d') #降维到3维时改为3，降维到2维时改为2\n",
    "\n",
    "        # 颜色归一化\n",
    "        norm = Normalize(vmin=0, vmax=100)\n",
    "        # 颜色映射\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "\n",
    "        for i in range(len(array_data)):\n",
    "            color_value = cmap(norm(score_value[i]))  # 根据分数设置颜色\n",
    "            if i == 0:\n",
    "                ax.scatter(array_data[i, 0], array_data[i, 1], array_data[i, 2], \n",
    "                        color=color_value, s=100, label='Start Point', marker='o')\n",
    "            elif i == len(array_data) - 1:\n",
    "                ax.scatter(array_data[i, 0], array_data[i, 1], array_data[i, 2], \n",
    "                        color=color_value, s=150, label='End Point', marker='o')\n",
    "            else:\n",
    "                ax.scatter(array_data[i, 0], array_data[i, 1], array_data[i, 2], \n",
    "                        color=color_value, s=50, marker='o')\n",
    "\n",
    "        # 添加颜色条\n",
    "        sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array(score_value)  # 设置颜色条的数据范围\n",
    "        fig.colorbar(sm, ax=ax, label='Score')\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_zlim(0, 1)\n",
    "        # 设置标签\n",
    "        ax.set_xlabel('Food dim 1')\n",
    "        ax.set_ylabel('Food dim2')\n",
    "        ax.set_zlabel('Food dim3')\n",
    "        # 设置标题\n",
    "        ax.set_title(f'3D Trajectory of food dim variance for p1 {subject_value} ')\n",
    "        # plt.legend()\n",
    "        image_filename = os.path.join(save_dir, f'3D Trajectory of food dim variance for P1 {subject_value} with score.png')\n",
    "        plt.savefig(image_filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一些函数，输入为combined_df中的probe/stick sequence\n",
    "\n",
    "# task1 得到被试探索的维度的数量\n",
    "def dim_probed(sequence):\n",
    "    dim_sequence = [next(iter(item)) if isinstance(item, dict) else item for item in sequence] #转换为代表维度的数字\n",
    "    int_dim_seq = [int(item) for item in dim_sequence] #转换为整型\n",
    "    dim_probed = len(set([num for num in int_dim_seq if num != 0]))\n",
    "    return dim_probed\n",
    "\n",
    "# task2 得到sequence中每个“线段”的长度（在一个维度里连续探索的次数）列表\n",
    "def probe_segments_length(sequence):\n",
    "    dim_sequence = [next(iter(item)) if isinstance(item, dict) else item for item in sequence]  #转换为代表维度的数字\n",
    "    int_dim_seq = [int(item) for item in dim_sequence]  #转换为整型\n",
    "    result = []\n",
    "    temp_list = []\n",
    "\n",
    "    # 遍历原始列表\n",
    "    for i, num in enumerate(int_dim_seq):\n",
    "        if num != 0:  # 非零数字\n",
    "            if not temp_list or temp_list[-1] == num:  # 当前段未开始或仍在同一段中\n",
    "                temp_list.append(num)\n",
    "            else:  # 开始新段\n",
    "                result.append(len(temp_list))  # 记录上一段长度\n",
    "                temp_list = [num]  # 重新初始化当前段\n",
    "        else:  # 遇到0，保存当前段并清空\n",
    "            if temp_list:\n",
    "                result.append(len(temp_list))  # 记录小列表长度\n",
    "                temp_list = []\n",
    "\n",
    "    # 处理最后一个非零段\n",
    "    if temp_list:\n",
    "        result.append(len(temp_list))\n",
    "\n",
    "    return result\n",
    "\n",
    "# task3 得到sequence中每个维度探索的总排列数（跨“线段”的总数）---- 可以先不做\n",
    "\n",
    "\n",
    "# task4 得到sequence中每个维度探索的次数（跨“线段”的总数）\n",
    "def dim_probe_counts(sequence):\n",
    "    from collections import Counter\n",
    "\n",
    "    dim_sequence = [next(iter(item)) if isinstance(item, dict) else item for item in sequence]  #转换为代表维度的数字\n",
    "    int_dim_seq = [int(item) for item in dim_sequence]  #转换为整型\n",
    "    non_zero_counts = Counter(num for num in int_dim_seq if num != 0)\n",
    "    result = list(non_zero_counts.values())\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#test\n",
    "sequence = combined_df1['Probe_sequence'][0]\n",
    "print(sequence)\n",
    "test_dimprobed = dim_probed(sequence)\n",
    "print(test_dimprobed)\n",
    "probe_segments = probe_segments_length(sequence)\n",
    "print(probe_segments)\n",
    "dim_probed_counts = dim_probe_counts(sequence)\n",
    "print(dim_probed_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回probe sequence的函数\n",
    "def probe_sequence(choice_sequence):\n",
    "    probe_sequence_list = []\n",
    "    data_int = choice_sequence.astype(int)\n",
    "    for trial in data_int:\n",
    "        round = np.array(trial, dtype=str)\n",
    "        probe_rank = {}\n",
    "        same_dim = {}\n",
    "        rank = {}\n",
    "        for blocks_idx, block in enumerate(round):\n",
    "            num_small_objects = len(block[0])\n",
    "            for i in range(num_small_objects):\n",
    "                if block[0][i] == block[1][i] == block[2][i]:\n",
    "                    same_dim[blocks_idx] = i\n",
    "                    rank[blocks_idx] = block[0][i]\n",
    "        if len(same_dim.keys()) == 3 and len(set(same_dim.values())) == 1 :\n",
    "            probe_rank[same_dim[0]+1] = rank[0]+rank[1]+rank[2]\n",
    "            probe_sequence_list.append(probe_rank)\n",
    "        else: probe_sequence_list.append(0)\n",
    "    return probe_sequence_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算probe fraction 函数\n",
    "def probe_fraction(choice_sequence):\n",
    "    data_int = choice_sequence.astype(int)\n",
    "    test_list = []\n",
    "    for trial in data_int:\n",
    "        trial_if_test = is_testing_trial(trial)\n",
    "        test_list.append(trial_if_test)\n",
    "    count_ones = sum(test_list)\n",
    "    total_length = len(test_list)\n",
    "    fraction = count_ones / total_length\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算stick fraction 函数\n",
    "def stick_fraction(choice_sequence):\n",
    "    data_int = choice_sequence.astype(int)\n",
    "    stick_list = []\n",
    "    for trial in data_int:\n",
    "        trial_if_stick = get_stick_trial(trial)\n",
    "        stick_list.append(trial_if_stick)\n",
    "    count_ones = sum(stick_list)\n",
    "    total_length = len(stick_list)\n",
    "    fraction = count_ones / total_length\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回stick sequence的函数\n",
    "def stick_sequence(choice_sequence):\n",
    "    stick_sequence_list = []\n",
    "    data_int = choice_sequence.astype(int)\n",
    "    for trial in data_int:\n",
    "        round = np.array(trial, dtype=str)\n",
    "        stick_food = {}\n",
    "        same_dim = {}\n",
    "        food_item = {}\n",
    "        for blocks_idx, block in enumerate(round):\n",
    "            num_small_objects = len(block[0])\n",
    "            for i in range(num_small_objects):\n",
    "                if block[0][i] == block[1][i] == block[2][i]:\n",
    "                    same_dim[blocks_idx] = i\n",
    "                    food_item[blocks_idx] = block[0][i]\n",
    "        if len(same_dim.keys()) == 1 and list(same_dim.keys())[0] == 0 :\n",
    "            stick_food[same_dim[0]+1] = food_item[0]\n",
    "            stick_sequence_list.append(stick_food)\n",
    "        else: stick_sequence_list.append(0)\n",
    "    return stick_sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从文件名中提取被试名\n",
    "def extract_key_From_filename(filename):\n",
    "    key = filename.split('_test3')[0]\n",
    "    prefix = key[:3].lower()\n",
    "    if prefix =='oct':\n",
    "        key = '10'+ key[3:]\n",
    "    elif prefix == 'nov':\n",
    "        key = '11' +key[3:]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid month prefix\") \n",
    "\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_behavour(data):\n",
    "    round_behavour =[]\n",
    "\n",
    "    for i in range(len(data['block1_fullChoice'])):  #遍历csv_block数据框的每一行，用fullchoice这一列来确定数据框的行数\n",
    "        B1=eval(data['block1_picChoice'].iloc[i].split('odict_keys')[1])\n",
    "        #使用 split('odict_keys') 将字符串按 'odict_keys' 分割，并取分割后的第二部分（[1]），这部分数据应该是一个字符串格式的列表。\n",
    "        #使用 eval() 将该字符串转换为实际的列表 B1。\n",
    "        B1_int = list(map(int, B1))\n",
    "        B2=eval(data['block2_picChoice'].iloc[i].split('odict_keys')[1])\n",
    "        B2_int = list(map(int, B2))\n",
    "        B3=eval(data['block3_picChoice'].iloc[i].split('odict_keys')[1])\n",
    "        B3_int = list(map(int, B3))\n",
    "        one_round=[B1_int,B2_int,B3_int]\n",
    "        round_behavour.append(one_round)\n",
    "\n",
    "    round_behavour=np.array(round_behavour)\n",
    "    return round_behavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_testing_trial(round):\n",
    "    same_dim = {}\n",
    "    round = np.array(round, dtype=str)\n",
    "    for blocks_idx, block in enumerate(round):\n",
    "        num_small_objects = len(block[0])\n",
    "        for i in range(num_small_objects):\n",
    "            if block[0][i] == block[1][i] == block[2][i]:\n",
    "                same_dim[blocks_idx] = i\n",
    "    if len(same_dim.keys()) == 3 and len(set(same_dim.values())) == 1 :\n",
    "        return  1\n",
    "    else:\n",
    "        return  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stick_trial(round):\n",
    "    same_dim = {}\n",
    "    round = np.array(round, dtype=str)\n",
    "    for blocks_idx, block in enumerate(round):\n",
    "        num_small_objects = len(block[0])\n",
    "        for i in range(num_small_objects):\n",
    "            if block[0][i] == block[1][i] == block[2][i]:\n",
    "                same_dim[blocks_idx] = i\n",
    "    if len(same_dim.keys()) == 1 and list(same_dim.keys())[0] == 0 :\n",
    "        return  1\n",
    "    else:\n",
    "        return  0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行分析的功能cell：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取原始csv数据，创建combined_df大表\n",
    "desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "directory_path1 = os.path.join(desktop_path, 'human_project_data', 'data_241118','human_data_forjiewen','p1_p2_csv','original_data')\n",
    "directory_path2 = os.path.join(desktop_path, 'human_project_data', 'data_241118','human_data_forjiewen','p2_only_csv','original_data')\n",
    "#创建初始dataframe（包含被试号，主特征，choice数组，分数数组，最高分数，反应时间数组（待加）\n",
    "\n",
    "phase={}\n",
    "mainfeature = {}\n",
    "choice_sequence = {}\n",
    "score_sequence = {}\n",
    "Max_score = {}\n",
    "for filename in sorted(os.listdir(directory_path1)):\n",
    "    if filename.endswith('csv'):\n",
    "        file_path = os.path.join(directory_path1, filename)\n",
    "        csv = pd.read_csv(file_path)\n",
    "        csv_block1 = csv[csv['phase']=='phase1']  #运行p2-only_group文件时改回csv_block\n",
    "        score = csv_block1['reward'].values\n",
    "        score_int = score.astype(int)\n",
    "        choice_sequence1 = get_round_behavour(csv_block1)\n",
    "        subject = extract_key_From_filename(filename)\n",
    "        #使用正则表达式提取mainfeature原字符串中的数字作为新字符串\n",
    "        mainfeature1 = csv_block1['p1Feature'].iloc[0] \n",
    "        mainfeature_num1 = re.findall(r'\\d+', mainfeature1)\n",
    "        mainfeature1 = ''.join(mainfeature_num1)\n",
    "        max_score =str(np.max(score_int))\n",
    "        phase[subject] = 'p1'\n",
    "        mainfeature[subject] = mainfeature1\n",
    "        choice_sequence[subject] = choice_sequence1\n",
    "        score_sequence[subject] = score_int\n",
    "        Max_score[subject] = max_score\n",
    "\n",
    "# 将所有字典放在一个列表中\n",
    "dict_list = [phase, mainfeature, choice_sequence, score_sequence, Max_score]\n",
    "# 构建 DataFrame\n",
    "df1 = pd.DataFrame(dict_list).T  # 转置使 key 成为第一列\n",
    "df1.columns = ['Phase', 'Mainfeature', 'Choice_sequence', 'Score_sequence', 'Max_score']  # 设置列名\n",
    "df1.reset_index(inplace=True)  # 重置索引，保留 key 作为第一列\n",
    "df1.rename(columns={'index': 'Subject'}, inplace=True)  # 将 'index' 列重命名为 'Key'\n",
    "\n",
    "phase={}\n",
    "mainfeature = {}\n",
    "choice_sequence = {}\n",
    "score_sequence = {}\n",
    "Max_score = {}\n",
    "for filename in sorted(os.listdir(directory_path1)):\n",
    "    if filename.endswith('csv'):\n",
    "        file_path = os.path.join(directory_path1, filename)\n",
    "        csv = pd.read_csv(file_path)\n",
    "        csv_block1 = csv[csv['phase']=='phase1']\n",
    "        csv_block2 = csv[csv['phase']=='phase2']  \n",
    "        score = csv_block2['reward'].values\n",
    "        score_int = score.astype(int)\n",
    "        choice_sequence2 = get_round_behavour(csv_block2)\n",
    "        subject = extract_key_From_filename(filename)\n",
    "        #使用正则表达式提取mainfeature原字符串中的数字作为新字符串\n",
    "        mainfeature2 = csv_block1['p2Feature'].iloc[0]\n",
    "        mainfeature2 = str(mainfeature2)  \n",
    "        mainfeature_num2 = re.findall(r'\\d+', mainfeature2)\n",
    "        mainfeature2 = ''.join(mainfeature_num2)\n",
    "        max_score =str(np.max(score_int))\n",
    "        phase[subject] = 'p2'\n",
    "        mainfeature[subject] = mainfeature2\n",
    "        choice_sequence[subject] = choice_sequence2\n",
    "        score_sequence[subject] = score_int\n",
    "        Max_score[subject] = max_score\n",
    "# 将所有字典放在一个列表中\n",
    "dict_list = [phase, mainfeature, choice_sequence, score_sequence, Max_score]\n",
    "# 构建 DataFrame\n",
    "df2 = pd.DataFrame(dict_list).T  # 转置使 key 成为第一列\n",
    "df2.columns = ['Phase', 'Mainfeature', 'Choice_sequence', 'Score_sequence', 'Max_score']  # 设置列名\n",
    "df2.reset_index(inplace=True)  # 重置索引，保留 key 作为第一列\n",
    "df2.rename(columns={'index': 'Subject'}, inplace=True)  # 将 'index' 列重命名为 'Key'\n",
    "\n",
    "phase={}\n",
    "Mainfeature = {}\n",
    "Choice_sequence = {}\n",
    "score_sequence = {}\n",
    "Max_score = {}\n",
    "for filename in sorted(os.listdir(directory_path2)):\n",
    "    if filename.endswith('csv'):\n",
    "        file_path = os.path.join(directory_path2, filename)\n",
    "        csv = pd.read_csv(file_path)\n",
    "        csv_block = csv[csv['phase']=='phase2']  \n",
    "        score = csv_block['reward'].values\n",
    "        score_int = score.astype(int)\n",
    "        choice_sequence = get_round_behavour(csv_block)\n",
    "        subject = extract_key_From_filename(filename)\n",
    "        #使用正则表达式提取mainfeature原字符串中的数字作为新字符串\n",
    "        mainfeature = csv_block['mainFeature'].iloc[0] \n",
    "        mainfeature_num = re.findall(r'\\d+', mainfeature)\n",
    "        mainfeature = ''.join(mainfeature_num)\n",
    "        max_score =str(np.max(score_int))\n",
    "        phase[subject] = 'p2only'\n",
    "        Mainfeature[subject] = mainfeature\n",
    "        Choice_sequence[subject] = choice_sequence\n",
    "        score_sequence[subject] = score_int\n",
    "        Max_score[subject] = max_score\n",
    "\n",
    "# 将所有字典放在一个列表中\n",
    "dict_list = [phase, Mainfeature, Choice_sequence, score_sequence, Max_score]\n",
    "# 构建 DataFrame\n",
    "df3 = pd.DataFrame(dict_list).T  # 转置使 key 成为第一列\n",
    "df3.columns = ['Phase', 'Mainfeature', 'Choice_sequence', 'Score_sequence', 'Max_score']  # 设置列名\n",
    "df3.reset_index(inplace=True)  # 重置索引，保留 key 作为第一列\n",
    "df3.rename(columns={'index': 'Subject'}, inplace=True)  # 将 'index' 列重命名为 'Key'\n",
    "\n",
    "print(f\"The shape of the df1 is: {df1.shape}\")\n",
    "print(f\"The shape of the df2 is: {df2.shape}\")\n",
    "print(f\"The shape of the df3 is: {df3.shape}\")\n",
    "\n",
    "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "data = combined_df['Choice_sequence']\n",
    "choice_seq = []\n",
    "for item in data:\n",
    "    choice_seq.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将choice sequence按food item 抽提整理为表格形式\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "\n",
    "def sort_digits(number, mainfeature):\n",
    "    digits = str(number)\n",
    "    mainfeature = str(mainfeature)\n",
    "    # 根据mainfeature的数字对数位进行排序\n",
    "    flag = np.zeros(len(digits))\n",
    "    index = []\n",
    "    for digit in mainfeature:\n",
    "        index.append(int(digit)-1)\n",
    "        flag[int(digit)-1] = 1\n",
    "    for i, item in enumerate(flag):\n",
    "        if item == 0:\n",
    "            index.append(i)\n",
    "    # 将排序后的数位重新组合成数字\n",
    "    digits = [digits[i] for i in index]\n",
    "    sorted_number = int(''.join(map(str, digits)))\n",
    "    return sorted_number\n",
    "\n",
    "def process_choice_sequence(choice_sequence, mainfeature):\n",
    "    _draw_digit = lambda x, i: str(x)[i] \n",
    "    flag = np.zeros(len(str(choice_sequence[0,0,0])))\n",
    "    index = []\n",
    "    for digit in mainfeature:\n",
    "        index.append(int(digit)-1)\n",
    "        flag[int(digit)-1] = 1\n",
    "    for i, item in enumerate(flag):\n",
    "        if item == 0:\n",
    "            index.append(i)\n",
    "\n",
    "    collect_round = []\n",
    "    for round in choice_sequence:\n",
    "        collect_feature = []\n",
    "        for i in index:\n",
    "            collect_phase = []\n",
    "            for phase in round:\n",
    "                collect_phase.append(f'{_draw_digit(phase[0], i)}{_draw_digit(phase[1], i)}{_draw_digit(phase[2], i)}')\n",
    "            collect_feature.append(collect_phase)\n",
    "        collect_round.append(collect_feature)\n",
    "    return collect_round\n",
    "\n",
    "# 处理DataFrame中的每一行\n",
    "# df['Processed_Choice_sequence'] = df.apply(lambda row: process_choice_sequence(row['Choice_sequence'], row['Mainfeature']), axis=1)\n",
    "\n",
    "wb = Workbook()\n",
    "tmp = wb.active\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    mainfeature = row['Mainfeature']\n",
    "    score = row['Score_sequence']\n",
    "    choice_subject = choice_seq[index]\n",
    "    output = process_choice_sequence(choice_subject, mainfeature)\n",
    "    output = np.array(output)\n",
    "\n",
    "    table = []\n",
    "    for i in range(output.shape[0]):\n",
    "        table_line = []\n",
    "        for j in range(output.shape[1]):\n",
    "            table_line.append(f'{output[i, j, 0]} {output[i, j, 1]} {output[i, j, 2]} ')\n",
    "            \n",
    "        table_line.append(f'{int(score[i])}')\n",
    "        table.append(table_line)\n",
    "        \n",
    "\n",
    "    phase_subject = f\"{row['Subject']}_{row['Phase']}\"  # 文件名\n",
    "    ws = wb.create_sheet(phase_subject)\n",
    "\n",
    "    for item in table:\n",
    "        ws.append(item)\n",
    "\n",
    "wb.save(\"rearrange_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算 probe sequence , probe fraction , stick sequence, stick fraciton加入大表作为新列\n",
    "combined_df['Probe_sequence'] = combined_df['Choice_sequence'].apply(probe_sequence)\n",
    "combined_df['Probe_fraction'] = combined_df['Choice_sequence'].apply(probe_fraction)\n",
    "combined_df['Stick_sequence'] = combined_df['Choice_sequence'].apply(stick_sequence)\n",
    "combined_df['Stick_fraction'] = combined_df['Choice_sequence'].apply(stick_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算Food_index_arr,Variance_arr, ---- for p2 p2only\n",
    "data_choicep1 = combined_df['Choice_sequence'][combined_df['Phase'] == 'p1']\n",
    "data_choicep2 = combined_df['Choice_sequence'][combined_df['Phase'] == 'p2']\n",
    "data_choicep2only = combined_df['Choice_sequence'][combined_df['Phase'] == 'p2only']\n",
    "\n",
    "data_p2_p2only = pd.concat([data_choicep2, data_choicep2only])\n",
    "#data_p2p2only_int = data_p2_p2only.astype(int)\n",
    "choice_data = data_p2_p2only.to_numpy()\n",
    "#包含p2p2only所有被试的food preference index ndarray的大列表\n",
    "food_index_list = [food_preference_arr(choice) for choice in choice_data] \n",
    "#将列表中所有的ndarray在垂直方向合并为大array用于统一做pca\n",
    "combined_array = np.vstack(food_index_list)\n",
    "\n",
    "pca = PCA(n_components = 3)  #降维到3维时改为3，降维到2维时改为2\n",
    "array_data = pca.fit_transform(combined_array)\n",
    "pca_weights = pca.components_  # Shape: (3, 12)\n",
    "\n",
    "# 打印权重\n",
    "for i, component in enumerate(pca_weights):\n",
    "    print(f\"PC{i+1} weights: {component}\")\n",
    "    \n",
    "#使用包含p2p2only所有被试的food preference index ndarray的大列表，创建有被试号Subject列对应的两列的dataframe\n",
    "#对food preference index列计算得到variance数组（x,x,x,x)对应1，2，3，4维度\n",
    "\n",
    "#获取被试号列表\n",
    "Subject_series_p2 = combined_df['Subject'][combined_df['Phase'] == 'p2']\n",
    "Subject_series_p2only = combined_df['Subject'][combined_df['Phase'] == 'p2only']\n",
    "Subject_series_p2p2only = pd.concat([Subject_series_p2, Subject_series_p2only], ignore_index=True)\n",
    "print(len(Subject_series_p2p2only), len(food_index_list))\n",
    "#构建包含‘Subject'列和‘Food_index_arr'两列的dataframe\n",
    "p2food_index_df = pd.DataFrame({\n",
    "    'Subject': Subject_series_p2p2only,  # 第一列\n",
    "    'Food_index_arr': food_index_list     # 第二列\n",
    "})\n",
    "#对Food_index_arr列应用函数得到Variance_arr列\n",
    "p2food_index_df['Variance_arr'] = p2food_index_df['Food_index_arr'].apply(get_dim_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算Food_index_arr,Variance_arr, ---- for p1\n",
    "data_choicep1 = combined_df['Choice_sequence'][combined_df['Phase'] == 'p1']\n",
    "choice_data = data_choicep1.to_numpy()\n",
    "#包含p1所有被试的food preference index ndarray的大列表\n",
    "food_index_list_p1 = [food_preference_arr(choice) for choice in choice_data] \n",
    "#将列表中所有的ndarray在垂直方向合并为大array用于统一做pca\n",
    "combined_array = np.vstack(food_index_list_p1)\n",
    "\n",
    "pca = PCA(n_components = 3)  #降维到3维时改为3，降维到2维时改为2\n",
    "array_data = pca.fit_transform(combined_array)\n",
    "pca_weights = pca.components_  # Shape: (3, 9)\n",
    "\n",
    "# 打印权重\n",
    "for i, component in enumerate(pca_weights):\n",
    "    print(f\"PC{i+1} weights: {component}\")\n",
    "    \n",
    "#使用包含p1所有被试的food preference index ndarray的大列表，创建有被试号Subject列对应的两列的dataframe\n",
    "#对food preference index列计算得到variance数组（x,x,x)对应1，2，3维度\n",
    "\n",
    "#获取被试号列表\n",
    "Subject_series_p1 = combined_df['Subject'][combined_df['Phase'] == 'p1']\n",
    "Mainfeature_series_p1 = combined_df['Mainfeature'][combined_df['Phase'] == 'p1']\n",
    "Score_series_p1 = combined_df['Score_sequence'][combined_df['Phase'] == 'p1']\n",
    "#将food_index_list_p1中食物顺序按照主特征字符串重新排序，主特征食物在前面6位\n",
    "def reorder_array_by_string(arr_list, order_str):\n",
    "    reordered_list = []\n",
    "    for idx, arr in enumerate(arr_list):\n",
    "        reordered_arr_subject = []\n",
    "        for round in arr:\n",
    "            # 将数组分组为3组\n",
    "            groups = [round[:3], round[3:6], round[6:]]\n",
    "            \n",
    "            # 根据字符串中的数字顺序重新排列分组\n",
    "            included_groups = [groups[int(i) - 1] for i in order_str[idx]]\n",
    "            excluded_groups = [groups[i] for i in range(3) if str(i + 1) not in order_str[idx]]\n",
    "            \n",
    "            # 合并包含的组和未包含的组\n",
    "            reordered_groups = included_groups + excluded_groups\n",
    "            \n",
    "            # 将重新排列的分组合并成一个数组\n",
    "            reordered_arr = [num for group in reordered_groups for num in group]\n",
    "            \n",
    "            reordered_arr_subject.append(reordered_arr)\n",
    "        reordered_list.append(reordered_arr_subject)\n",
    "\n",
    "    return reordered_list\n",
    "\n",
    "reordered_food_index_list_p1 = reorder_array_by_string(food_index_list_p1,Mainfeature_series_p1 )\n",
    "\n",
    "print(len(Subject_series_p1), len(food_index_list_p1))\n",
    "#构建包含‘Subject'列和‘Food_index_arr'两列的dataframe\n",
    "p1food_index_df = pd.DataFrame({\n",
    "    'Subject': Subject_series_p1,  # 第一列\n",
    "    'Food_index_arr_reordered': reordered_food_index_list_p1,  # 第二列\n",
    "    'Score_sequence':Score_series_p1\n",
    "})\n",
    "\n",
    "#对Food_index_arr列应用函数得到Variance_arr列\n",
    "p1food_index_df['Variance_arr'] = p1food_index_df['Food_index_arr_reordered'].apply(get_dim_variance)\n",
    "\n",
    "#定义文件保存路径\n",
    "fig_save_dir1 = os.path.join(desktop_path, 'food dim variance plot test','for p1')\n",
    "fig_save_dir2 = os.path.join(desktop_path, 'food dim variance plot test','for p1 with score')\n",
    "#3D 可视化\n",
    "plot_3d_trace(p1food_index_df, 'Variance_arr', 'Subject','Score_sequence', fig_save_dir1 )\n",
    "#plot_3d_trace_score(p1food_index_df, 'Variance_arr', 'Subject','Score_sequence', fig_save_dir2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从endsurvey indicator 文件中导入food dim if correct1 , spearman corr, identified dim number, 加到combined_df中p2和p2only的数据,作为新df：df_analysis1\n",
    "desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "directory_path = os.path.join(desktop_path, 'human_project_data','indicator_csv')\n",
    "file_path1 = os.path.join(directory_path, 'p2 food dim answer indicator.csv')\n",
    "file_path2 = os.path.join(directory_path, 'p2only food dim answer indicator.csv')\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "p2_data = combined_df[combined_df['Phase'] == 'p2']\n",
    "p2only_data = combined_df[combined_df['Phase'] == 'p2only']\n",
    "\n",
    "p2_data['Subject'] = p2_data['Subject'].astype(str)  # 或者 int，根据数据情况\n",
    "p2only_data['Subject'] = p2only_data['Subject'].astype(str)\n",
    "df1['Subject'] = df1['Subject'].astype(str)  # 确保与 combined_df 一致\n",
    "df2['Subject'] = df2['Subject'].astype(str)  # 确保与 combined_df 一致\n",
    "\n",
    "df_analysis_p2 = pd.merge(p2_data, df1[['Subject', 'If correct1','Correlation coefficient','Identified number']], on='Subject', how='left')\n",
    "df_analysis_p2only = pd.merge(p2only_data, df2[['Subject', 'If correct1','Correlation coefficient','Identified number']], on='Subject', how='left')\n",
    "df_analysis1 = pd.concat([df_analysis_p2, df_analysis_p2only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of people had correct answer for each category of food type mentioning\n",
    "#for p2 p2only data, identified number missing value 的就先去掉了\n",
    "mention_one = df_analysis1[df_analysis1['Identified number']== 1]\n",
    "mention_two = df_analysis1[df_analysis1['Identified number']== 2]\n",
    "mention_three = df_analysis1[df_analysis1['Identified number']== 3]\n",
    "mention_four = df_analysis1[df_analysis1['Identified number']== 4]\n",
    "mention_one_correct = mention_one[mention_one['If correct1']==1]\n",
    "mention_two_correct = mention_two[mention_two['If correct1']==1]\n",
    "mention_three_correct = mention_three[mention_three['If correct1']==1]\n",
    "mention_four_correct = mention_four[mention_four['If correct1']==1]\n",
    "fraction1 = len(mention_one_correct) / len(mention_one)\n",
    "fraction2 = len(mention_two_correct) / len(mention_two)\n",
    "fraction3 = len(mention_three_correct) / len(mention_three)\n",
    "fraction4 = len(mention_four_correct) / len(mention_four)\n",
    "print(len(mention_one_correct))\n",
    "print(len(mention_one))\n",
    "print(len(mention_two_correct))\n",
    "print(len(mention_two))\n",
    "print(len(mention_three_correct))\n",
    "print(len(mention_three))\n",
    "print(len(mention_four_correct) )\n",
    "print(len(mention_four))\n",
    "\n",
    "#FPR-food dim, 2group\n",
    "x1 = fraction1\n",
    "x2 = fraction2\n",
    "x3 = fraction3\n",
    "x4 = fraction4\n",
    "values = [x1, x2, x3, x4]\n",
    "percentages = [x * 100 for x in values]\n",
    "labels = ['correct with one dim mentioned','correct with two dim mentioned','correct with three dim mentioned','correct with four dim mentioned' ]\n",
    "fig,ax = plt.subplots()\n",
    "bars = plt.bar(labels, percentages, color = [ 'darkgrey','gainsboro','dimgrey','silver'],hatch=['**','**','**','**'])\n",
    "plt.title('Comparison of fraction correct for 4 category of dimention identification')\n",
    "plt.xlabel('Conditions')\n",
    "plt.ylabel('Percentage of fraction correct')\n",
    "#plt.ylim(0,50)\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 1), ha='center', va='bottom')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional analysis on full score or correct identification of types—>complete both true and null conditions\n",
    "df_analysis1['If correct1'] = df_analysis1['If correct1'].fillna(0)\n",
    "full_score_correct = df_analysis1[(df_analysis1['Max_score'] == '100') & (df_analysis1['If correct1']== 1)]\n",
    "full_score_not_correct = df_analysis1[(df_analysis1['Max_score'] == '100') & (df_analysis1['If correct1']!= 1)]\n",
    "not_full_score_correct = df_analysis1[(df_analysis1['Max_score'] != '100') & (df_analysis1['If correct1']== 1)]\n",
    "not_full_score_not_correct = df_analysis1[(df_analysis1['Max_score'] != '100') & (df_analysis1['If correct1']!= 1)]\n",
    "Tp = len(full_score_correct.to_numpy())\n",
    "Fn = len(not_full_score_not_correct.to_numpy())\n",
    "Fp = len(not_full_score_correct.to_numpy())\n",
    "Tn = len(full_score_not_correct.to_numpy())\n",
    "print(f'tp={Tp},fn={Fn},fp={Fp},tn={Tn}')\n",
    "conf_matrix =  np.array([[Tp,Tn],\n",
    "                         [Fp,Fn]])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['answer correct', 'answer not correct'], \n",
    "            yticklabels=['full score', 'not fullscore'])\n",
    "\n",
    "# 添加标题\n",
    "plt.title('Confusion Matrix of if full score and answer if correct for all subject in p2 and p2only',fontsize=14)\n",
    "plt.xlabel(\"answer if correct\")\n",
    "plt.ylabel('if full score')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对correct / not correct 画stick fraction小提琴图 ---------没有显著性差异\n",
    "datap2 = df_analysis1[df_analysis1['Phase'] == 'p2']\n",
    "stickfraction_correct  = pd.to_numeric(datap2['Probe_fraction'][datap2['If correct1']==1])\n",
    "stickfraction_not_correct = pd.to_numeric(datap2['Probe_fraction'][datap2['If correct1']==0])\n",
    "\n",
    "group1 = stickfraction_correct.to_numpy()\n",
    "group2 = stickfraction_not_correct.to_numpy() \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Group\": [\"Answer correct\"] * len(group1) + [\"Answer not correct\"] * len(group2),\n",
    "    \"Value\": np.concatenate([group1, group2]),\n",
    "    \"ColorGroup\": [\"Answer correct\"] * len(group1) + [\"Answer not correct\"] * len(group2)  # 添加颜色分组\n",
    "})\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.violinplot(x=\"Group\", y=\"Value\", data=df, inner=None, color='pink', linewidth=1.5, alpha=0.2)\n",
    "sns.stripplot(x=\"Group\", y=\"Value\", data=df, jitter=True, size=5, hue=\"ColorGroup\", palette={\"Answer correct\": \"grey\", \"Answer not correct\": \"gainsboro\"}, alpha=0.8)\n",
    "\n",
    "for group in df[\"Group\"].unique():\n",
    "    group_values = df[df[\"Group\"] == group][\"Value\"]\n",
    "    median = np.median(group_values)\n",
    "    mean = np.mean(group_values)\n",
    "    q1 = np.percentile(group_values, 25)\n",
    "    q3 = np.percentile(group_values, 75)\n",
    "    \n",
    "    x_pos = list(df[\"Group\"].unique()).index(group)\n",
    "\n",
    "    plt.scatter(x_pos, median, color=\"red\", label=\"Median\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, mean, color=\"green\", label=\"Mean\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q1, color=\"purple\", label=\"Q1 (25th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q3, color=\"orange\", label=\"Q3 (75th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.title(\"Stick fraction for subject with correct/not correct answer\", fontsize=16)\n",
    "plt.xlabel(\"Group\", fontsize=14)\n",
    "plt.ylabel(\"Stick fraction\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2, equal_var=False)  # 设置 equal_var=False 假设方差不相等\n",
    "print(f\"T-test: t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "# 判断显著性\n",
    "if p_value < 0.05:\n",
    "    print(\"两组之间的差异具有统计学意义（p < 0.05）。\")\n",
    "else:\n",
    "    print(\"两组之间的差异不具有统计学意义（p >= 0.05）。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从endsurvey indicator 文件中导入food item spearman corr, identified food number, 加到combined_df中,作为新df：df_analysis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从原始probe sequence中得到用分数排序并提取了probe维度数字的sequence\n",
    "def convert_probe_list_for_food_item(probe_list):\n",
    "    return [next(iter(item.values()))[0] if isinstance(item, dict) else item for item in probe_list]\n",
    "combined_df1 = combined_df[combined_df['Phase'] == 'p1'].sort_values(by='Max_score', ascending=True)\n",
    "all_probe_list_p1 = combined_df1['Stick_sequence'] \n",
    "probe_food_list_p1 = [convert_probe_list_for_food_item(probe_list) for probe_list in all_probe_list_p1]\n",
    "combined_df2 = combined_df[combined_df['Phase'] == 'p2'].sort_values(by='Max_score', ascending=True)\n",
    "all_probe_list_p2 = combined_df2['Stick_sequence'] \n",
    "probe_food_list_p2 = [convert_probe_list_for_food_item(probe_list) for probe_list in all_probe_list_p2]\n",
    "combined_df2only = combined_df[combined_df['Phase'] == 'p2only'].sort_values(by='Max_score', ascending=True)\n",
    "all_probe_list_p2only = combined_df2only['Stick_sequence'] \n",
    "probe_food_list_p2only = [convert_probe_list_for_food_item(probe_list) for probe_list in all_probe_list_p2only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用probe sequence 画热图可视化probe的维度, 画stick sequence时进行替换\n",
    "\n",
    "# combined_df1 = combined_df[combined_df['Phase'] == 'p1'].sort_values(by='Max_score', ascending=True)\n",
    "# combined_df2 = combined_df[combined_df['Phase'] == 'p2'].sort_values(by='Max_score', ascending=True)\n",
    "# combined_df2only = combined_df[combined_df['Phase'] == 'p2only'].sort_values(by='Max_score', ascending=True)\n",
    "\n",
    "\n",
    "# all_probe_list_p1 = combined_df1['Stick_sequence'] \n",
    "subject_list_p1 = combined_df1['Subject']\n",
    "mainfeature_list_p1 = combined_df1['Mainfeature']\n",
    "\n",
    "# all_probe_list_p2 = combined_df2['Stick_sequence']\n",
    "subject_list_p2 = combined_df2['Subject']\n",
    "mainfeature_list_p2 = combined_df2['Mainfeature']\n",
    "\n",
    "# all_probe_list_p2only = combined_df2only['Stick_sequence']\n",
    "subject_list_p2only = combined_df2only['Subject']\n",
    "mainfeature_list_p2only = combined_df2only['Mainfeature']\n",
    "\n",
    "\n",
    "#将list中的字典元素转换为字典key的值，0保持为0\n",
    "def convert_probe_list(probe_list):\n",
    "    return [next(iter(item)) if isinstance(item, dict) else item for item in probe_list]\n",
    "\n",
    "\n",
    "\n",
    "# 修改all_probe_list_p1, all_probe_list_p2, all_probe_list_p2only\n",
    "all_probe_list_p1 = [convert_probe_list(probe_list) for probe_list in all_probe_list_p1]\n",
    "all_probe_list_p2 = [convert_probe_list(probe_list) for probe_list in all_probe_list_p2]\n",
    "all_probe_list_p2only = [convert_probe_list(probe_list) for probe_list in all_probe_list_p2only]\n",
    "\n",
    "# 为每个列表补齐长度并转换为ndarray\n",
    "max_length1 = max(len(lst) for lst in all_probe_list_p1)\n",
    "end_p1 = [len(lst) for lst in all_probe_list_p1]\n",
    "data_visualize1 = [lst + [0] * (max_length1 - len(lst)) for lst in all_probe_list_p1]\n",
    "food_visualize1 = [lst + [0] * (max_length1 - len(lst)) for lst in probe_food_list_p1]\n",
    "data_array_p1 = np.array(data_visualize1) # data_array_ 是最终用来画图的数据\n",
    "food_array_p1 = np.array(food_visualize1)\n",
    "food_array_p1_skip0 = np.where(food_array_p1 == '0', ' ', food_array_p1)\n",
    "#制作ystick array\n",
    "subject_array_p1 = np.array(subject_list_p1)\n",
    "mainfeature_array_p1 = np.array(mainfeature_list_p1) # 可用于判断probe的维度是否为重要维度\n",
    "ystick_arr_p1 = subject_array_p1 + '_' + mainfeature_array_p1\n",
    "#制作终点标记 array\n",
    "end_arr_p1 = np.array(end_p1)\n",
    "\n",
    "max_length2 = max(len(lst) for lst in all_probe_list_p2)\n",
    "end_p2 = [len(lst) for lst in all_probe_list_p2]\n",
    "data_visualize2 = [lst + [0] * (max_length2 - len(lst)) for lst in all_probe_list_p2]\n",
    "data_array_p2 = np.array(data_visualize2) # data_array_ 是最终用来画图的数据\n",
    "food_visualize2 = [lst + [0] * (max_length2 - len(lst)) for lst in probe_food_list_p2]\n",
    "food_array_p2 = np.array(food_visualize2)\n",
    "food_array_p2_skip0 = np.where(food_array_p2 == '0', ' ', food_array_p2)\n",
    "subject_array_p2 = np.array(subject_list_p2)\n",
    "mainfeature_array_p2 = np.array(mainfeature_list_p2) # 可用于判断probe的维度是否为重要维度\n",
    "ystick_arr_p2 = subject_array_p2 + '_' + mainfeature_array_p2\n",
    "end_arr_p2 = np.array(end_p2)\n",
    "\n",
    "max_length3 = max(len(lst) for lst in all_probe_list_p2only)\n",
    "end_p2only = [len(lst) for lst in all_probe_list_p2only]\n",
    "data_visualize3 = [lst + [0] * (max_length3 - len(lst)) for lst in all_probe_list_p2only]\n",
    "data_array_p2only = np.array(data_visualize3)  # data_array_ 是最终用来画图的数据\n",
    "food_visualize2only = [lst + [0] * (max_length3 - len(lst)) for lst in probe_food_list_p2only]\n",
    "food_array_p2only = np.array(food_visualize2only)\n",
    "food_array_p2only_skip0 = np.where(food_array_p2only == '0', ' ', food_array_p2only)\n",
    "subject_array_p2only = np.array(subject_list_p2only)\n",
    "mainfeature_array_p2only = np.array(mainfeature_list_p2only) # 可用于判断probe的维度是否为重要维度\n",
    "ystick_arr_p2only = subject_array_p2only + '_' + mainfeature_array_p2only\n",
    "end_arr_p2only = np.array(end_p2only)\n",
    "\n",
    "#heatmap for p1/p2/p2only (画的时候换参数)\n",
    "fig, ax = plt.subplots(figsize=(60, 15))  # 设置图像大小\n",
    "cax = ax.matshow(data_array_p2, cmap=\"viridis\")  # 使用 'viridis' 颜色映射，也可以换成其他 cmap\n",
    "cbar = plt.colorbar(cax, ax=ax)\n",
    "cbar.set_label('Values (0-4)', rotation=270, labelpad=15)  # 设置颜色条标题\n",
    "\n",
    "# 在热图上标注数字\n",
    "for i in range(data_array_p2.shape[0]):\n",
    "    for j in range(data_array_p2.shape[1]):\n",
    "        ax.text(j, i, str(food_array_p2_skip0[i, j]), ha='center', va='center', color='white', fontsize=16)\n",
    "#终点标记\n",
    "ax.scatter(end_arr_p2, range(len(end_arr_p2)), color=\"crimson\", label=\"End Points\", s=100, edgecolors=\"black\")\n",
    "# 设置坐标轴\n",
    "ax.set_xticks(range(data_array_p2.shape[1]))\n",
    "ax.set_yticks(range(data_array_p2.shape[0])) \n",
    "ax.set_yticklabels(ystick_arr_p2, fontsize=15)\n",
    "ax.set_xlabel('Trial number', fontsize=15)\n",
    "ax.set_ylabel('Subject_Mainfeature', fontsize=15)\n",
    "ax.set_title('visualization of three-block probe dim for p2', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在上一个cell 的基础上，根据Mainfeature,把主特征改为2，非主特征改为4 \n",
    "#数据：data_array_p1，data_array_p2，data_array_p2only\n",
    "\n",
    "def main_nonmain_feature(arr_2d, arr_1d):\n",
    "    arr = np.zeros(arr_2d.shape, dtype=int)\n",
    "    for i in range(arr_2d.shape[0]):  # 遍历二维数组的行\n",
    "        unmatched_count = []\n",
    "        for j in range(arr_2d.shape[1]):  # 遍历每行中的元素\n",
    "            current_value = str(arr_2d[i, j])\n",
    "            compare_str = arr_1d[i]\n",
    "            if current_value == '0':\n",
    "                arr[i,j] = 0\n",
    "            elif current_value in compare_str:\n",
    "                # 如果当前值在对应行的字符串中\n",
    "                if current_value == compare_str[0]:\n",
    "                    arr[i, j] = 1  # 如果是第一位数字\n",
    "                elif current_value == compare_str[1]:\n",
    "                    arr[i, j] = 2  # 如果是第二位数字\n",
    "            else:\n",
    "                unmatched_count.append(current_value)\n",
    "                array = np.array(unmatched_count)\n",
    "                array_unique = np.unique(array)\n",
    "                if len(array_unique) == 1:\n",
    "                    arr[i,j] = 3\n",
    "                elif len(array_unique) == 2:\n",
    "                    if current_value == array[0]:\n",
    "                        arr[i,j] = 3\n",
    "                    else: arr[i,j] = 4\n",
    "    return arr\n",
    "\n",
    "\n",
    "#对p1 data进行revert\n",
    "data_p1_revert = main_nonmain_feature(data_array_p1,mainfeature_array_p1) # 是用于画图的数据\n",
    "# #p2\n",
    "data_p2_revert = main_nonmain_feature(data_array_p2,mainfeature_array_p2) # 是用于画图的数据\n",
    "#p2only\n",
    "data_p2only_revert = main_nonmain_feature(data_array_p2only,mainfeature_array_p2only)\n",
    "\n",
    "#画图部分\n",
    "colors = ['snow', '#FFCCCB', '#FF8C00', '#87CEFA','#0000FF']  # 灰色、暖色（浅红和橙色）、冷色（浅蓝和深蓝） #p2p2only加颜色 '#0000FF'\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5 ]  # 每个颜色的边界  #p2p2only加边界 4.5\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "heatmap = plt.imshow(data_p2only_revert, cmap=cmap, norm=norm, aspect='auto') #p1p2p2only\n",
    "\n",
    "# 添加颜色图例\n",
    "colorbar = plt.colorbar(heatmap, ticks=[0, 1, 2, 3, 4])        #p1 p2p2only 改\n",
    "colorbar.set_label('Value', fontsize=12)\n",
    "colorbar.ax.set_yticklabels(['non-probe', 'relevant dim1', 'relevant dim2', \n",
    "                             'irrelevant dim1','irrelevant dim2'])            #p1 p2p2only 改\n",
    "\n",
    "\n",
    "\n",
    "# 设置标题和轴标签\n",
    "plt.title('Heatmap of one-block probe bahavior for p2only group', fontsize=16)  #p1p2p2only\n",
    "plt.xlabel('Rounds', fontsize=14)\n",
    "plt.ylabel('Subjects', fontsize=14)\n",
    "\n",
    "# 设置刻度\n",
    "ax = plt.gca()  # 获取当前 Axes\n",
    "#标注probe的该维度里的具体食物（第一排）\n",
    "for i in range(data_array_p2only.shape[0]): #p1p2p2only\n",
    "    for j in range(data_array_p2only.shape[1]):  #p1p2p2only\n",
    "        ax.text(j, i, str(food_array_p2only_skip0[i, j]), ha='center', va='center', color='firebrick', fontsize=10)  #p1p2p2only\n",
    "ax.set_xticks(range(data_p2only_revert.shape[1])) #p1p2p2only\n",
    "ax.set_yticks(range(data_p2only_revert.shape[0])) #p1p2p2only\n",
    "ax.set_yticklabels([f'{subject_array_p2only[i]}' for i in range(data_p2only_revert.shape[0])], fontsize=10)  # 自定义 y 轴标签  #两处p1p2p2only\n",
    "ax.set_xticklabels([f'{j+1}' for j in range(data_p2only_revert.shape[1])], fontsize=10, rotation=90)  # 自定义 x 轴标签  #p1p2p2only\n",
    "ax.scatter(end_arr_p2only, range(len(end_arr_p2only)), color=\"green\", label=\"End Points\", s=50, edgecolors=\"black\")  #两处p1p2p2only\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 P1 endsurvey 中的indicator加入combined_p1 df中作为 analysis_p1\n",
    "desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "directory_path = os.path.join(desktop_path, 'human_project_data','indicator_csv')\n",
    "file_path = os.path.join(directory_path, 'p1 food item answer indicator.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "p1_data = combined_df[combined_df['Phase'] == 'p1']\n",
    "\n",
    "p1_data['Subject'] = p1_data['Subject'].astype(str)  # 或者 int，根据数据情况\n",
    "df['Subject'] = df['Subject'].astype(str)  # 确保与 combined_df 一致\n",
    "\n",
    "df_analysis_p1 = pd.merge(p1_data, df[['Subject', 'Correlation coefficient','False positive rate','Identified number']], on='Subject', how='left')\n",
    "df_analysis_p1 = df_analysis_p1.dropna(subset=['Correlation coefficient'])\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "sns.reset_defaults()\n",
    "\n",
    "x = pd.to_numeric(df_analysis_p1['Stick_fraction'], errors='coerce')\n",
    "y = pd.to_numeric(df_analysis_p1['Correlation coefficient'], errors='coerce')\n",
    "corr, p_value = pearsonr(x, y)#计算斯皮尔曼相关系数\n",
    "data = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "data[\"count\"] = data.groupby([\"x\", \"y\"])[\"x\"].transform(\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.scatterplot(x=\"x\", y=\"y\", size=\"count\", sizes=(20, 200), hue=\"count\", palette=\"viridis\", data=data, ax=ax, legend=\"brief\")\n",
    "ax.legend(\n",
    "    title=\"Count\",          # 图例标题\n",
    "    bbox_to_anchor=(1.05, 1),  # 图例框位置 (x, y)\n",
    "    loc=\"upper left\",       # 图例锚点\n",
    "    borderaxespad=0.        # 图例与轴之间的间距\n",
    ")\n",
    "\n",
    "sns.regplot(x=x, y=y, ax=ax, scatter=False, line_kws={'color': 'grey'})\n",
    "ax.set_title(f'Answer corr with stick fraction for p1 group', fontsize = 15)\n",
    "ax.set_xlabel( \" stick fraction \",fontsize = 14)\n",
    "ax.set_ylabel('Answer corr',fontsize = 14)\n",
    "ax.text(0.1,0.99, f'Pearson corr: {corr:.2f},P-value:{p_value:.2f}',fontsize = 13, color = 'grey', ha='left', va='top',transform=ax.transAxes )\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1 answer false positive rate/corr with probe/stick fration\n",
    "from scipy.stats import pearsonr\n",
    "sns.reset_defaults()\n",
    "\n",
    "df_analysis_p1 = df_analysis_p1.dropna(subset=['False positive rate'])\n",
    "\n",
    "x = pd.to_numeric(df_analysis_p1['Stick_fraction'], errors='coerce')\n",
    "y = pd.to_numeric(df_analysis_p1['False positive rate'], errors='coerce')\n",
    "corr, p_value = spearmanr(x, y)#计算斯皮尔曼相关系数\n",
    "data = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "data[\"count\"] = data.groupby([\"x\", \"y\"])[\"x\"].transform(\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.scatterplot(x=\"x\", y=\"y\", size=\"count\", sizes=(20, 200), hue=\"count\", palette=\"viridis\", data=data, ax=ax, legend=\"brief\")\n",
    "ax.legend(\n",
    "    title=\"Count\",          # 图例标题\n",
    "    bbox_to_anchor=(1.05, 1),  # 图例框位置 (x, y)\n",
    "    loc=\"upper left\",       # 图例锚点\n",
    "    borderaxespad=0.        # 图例与轴之间的间距\n",
    ")\n",
    "\n",
    "sns.regplot(x=x, y=y, ax=ax, scatter=False, line_kws={'color': 'grey'})\n",
    "ax.set_title(f'FPR with stick fraction for p1 group', fontsize = 15)\n",
    "ax.set_xlabel( \" Stick fraction \",fontsize = 14)\n",
    "ax.set_ylabel('FPR',fontsize = 14)\n",
    "ax.text(0.1,0.99, f'Spearman corr: {corr:.2f},P-value:{p_value:.2f}',fontsize = 13, color = 'grey', ha='left', va='top',transform=ax.transAxes )\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probe fraction with score\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "sns.reset_defaults()\n",
    "\n",
    "x = pd.to_numeric(combined_df1['Stick_fraction'], errors='coerce')\n",
    "y = pd.to_numeric(combined_df1['Max_score'], errors='coerce')\n",
    "corr, p_value = spearmanr(x, y)#计算斯皮尔曼相关系数\n",
    "data = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "data[\"count\"] = data.groupby([\"x\", \"y\"])[\"x\"].transform(\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.scatterplot(x=\"x\", y=\"y\", size=\"count\", sizes=(20, 200), hue=\"count\", palette=\"viridis\", data=data, ax=ax, legend=\"brief\")\n",
    "ax.legend(\n",
    "    title=\"Count\",          # 图例标题\n",
    "    bbox_to_anchor=(1.05, 1),  # 图例框位置 (x, y)\n",
    "    loc=\"upper left\",       # 图例锚点\n",
    "    borderaxespad=0.        # 图例与轴之间的间距\n",
    ")\n",
    "\n",
    "sns.regplot(x=x, y=y, ax=ax, scatter=False, line_kws={'color': 'grey'})\n",
    "ax.set_title(f'Stick fraction with score for p1 group all subject', fontsize = 15)\n",
    "ax.set_xlabel( \" One-block probe fraction \",fontsize = 14)\n",
    "ax.set_ylabel('The highest score of subject',fontsize = 14)\n",
    "ax.text(0.1,0.99, f'Pearson corr: {corr:.2f},P-value:{p_value:.2f}',fontsize = 13, color = 'grey', ha='left', va='top',transform=ax.transAxes )\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 提取non-stick subject的最高分数，stick subject的最高分数，用提亲图画分数分布和均值，作统计检验\n",
    "score_non_stick  = pd.to_numeric(combined_df1['Max_score'][combined_df['Stick_fraction']==0])\n",
    "score_stick = pd.to_numeric(combined_df['Max_score'][combined_df['Stick_fraction'] != 0])\n",
    "\n",
    "group1 = score_non_stick.to_numpy()\n",
    "group2 = score_stick.to_numpy() \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Group\": [\"non_stick\"] * len(group1) + [\"stick\"] * len(group2),\n",
    "    \"Value\": np.concatenate([group1, group2]),\n",
    "    \"ColorGroup\": [\"non_stick\"] * len(group1) + [\"stick\"] * len(group2)  # 添加颜色分组\n",
    "})\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.violinplot(x=\"Group\", y=\"Value\", data=df, inner=None, color='pink', linewidth=1.5, alpha=0.1)\n",
    "sns.stripplot(x=\"Group\", y=\"Value\", data=df, jitter=True, size=5, hue=\"ColorGroup\", palette={\"non_stick\": \"grey\", \"stick\": \"gainsboro\"}, alpha=0.8)\n",
    "\n",
    "for group in df[\"Group\"].unique():\n",
    "    group_values = df[df[\"Group\"] == group][\"Value\"]\n",
    "    median = np.median(group_values)\n",
    "    mean = np.mean(group_values)\n",
    "    q1 = np.percentile(group_values, 25)\n",
    "    q3 = np.percentile(group_values, 75)\n",
    "    \n",
    "    x_pos = list(df[\"Group\"].unique()).index(group)\n",
    "\n",
    "    plt.scatter(x_pos, median, color=\"red\", label=\"Median\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, mean, color=\"green\", label=\"Mean\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q1, color=\"purple\", label=\"Q1 (25th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q3, color=\"orange\", label=\"Q3 (75th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.title(\"Maxscore for subjects with/without sticking behavior\", fontsize=16)\n",
    "plt.xlabel(\"Group\", fontsize=14)\n",
    "plt.ylabel(\"Counts\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2, equal_var=False)  # 设置 equal_var=False 假设方差不相等\n",
    "print(f\"T-test: t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "# 判断显著性\n",
    "if p_value < 0.05:\n",
    "    print(\"两组之间的差异具有统计学意义（p < 0.05）。\")\n",
    "else:\n",
    "    print(\"两组之间的差异不具有统计学意义（p >= 0.05）。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probe fraction/stick fraction for subject with full/nonfull score for p2\n",
    "#p2_data = combined_df[combined_df['Phase']== 'p2only']\n",
    "probe_fraction_full_score  = pd.to_numeric(combined_df1['Stick_fraction'][combined_df1['Max_score']== '100'])\n",
    "probe_fraction_not_full_score = pd.to_numeric(combined_df1['Stick_fraction'][combined_df1['Max_score']!= '100'])\n",
    "group1 = probe_fraction_full_score.to_numpy()\n",
    "group2 = probe_fraction_not_full_score.to_numpy() \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Group\": [\"full score\"] * len(group1) + [\"not full score\"] * len(group2),\n",
    "    \"Value\": np.concatenate([group1, group2]),\n",
    "    \"ColorGroup\": [\"full score\"] * len(group1) + [\"not full score\"] * len(group2)  # 添加颜色分组\n",
    "})\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.violinplot(x=\"Group\", y=\"Value\", data=df, inner=None, color='pink', linewidth=1.5, alpha=0.2)\n",
    "sns.stripplot(x=\"Group\", y=\"Value\", data=df, jitter=True, size=5, hue=\"ColorGroup\", palette={\"full score\": \"grey\", \"not full score\": \"gainsboro\"}, alpha=0.8)\n",
    "\n",
    "for group in df[\"Group\"].unique():\n",
    "    group_values = df[df[\"Group\"] == group][\"Value\"]\n",
    "    median = np.median(group_values)\n",
    "    mean = np.mean(group_values)\n",
    "    q1 = np.percentile(group_values, 25)\n",
    "    q3 = np.percentile(group_values, 75)\n",
    "    \n",
    "    x_pos = list(df[\"Group\"].unique()).index(group)\n",
    "\n",
    "    plt.scatter(x_pos, median, color=\"red\", label=\"Median\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, mean, color=\"green\", label=\"Mean\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q1, color=\"purple\", label=\"Q1 (25th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q3, color=\"orange\", label=\"Q3 (75th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.title(\"One-block probe fraction for subject with full/not full score for p1 group\", fontsize=16)\n",
    "plt.xlabel(\"Group\", fontsize=14)\n",
    "plt.ylabel(\"Stick fraction\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2, equal_var=False)  # 设置 equal_var=False 假设方差不相等\n",
    "print(f\"T-test: t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "# 判断显著性\n",
    "if p_value < 0.05:\n",
    "    print(\"两组之间的差异具有统计学意义（p < 0.05）。\")\n",
    "else:\n",
    "    print(\"两组之间的差异不具有统计学意义（p >= 0.05）。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用probe sequence 画不同组被试的probe frequency on trial course， 可视化stick sequence 时 将‘Probe_sequence'替换\n",
    "all_probe_list_p1 = combined_df['Stick_sequence'][combined_df['Phase'] == 'p1']\n",
    "all_stick_list_p1 = combined_df['Stick_sequence'][combined_df['Phase'] == 'p1'] # 用于同时画p1的probe 和 stick trial\n",
    "all_probe_list_p2 = combined_df['Stick_sequence'][combined_df['Phase'] == 'p2']\n",
    "all_probe_list_p2only = combined_df['Stick_sequence'][combined_df['Phase'] == 'p2only']\n",
    "\n",
    "#将list中的字典元素转换为1，0保持为0\n",
    "def convert_probe_list(probe_list):\n",
    "    return [1 if isinstance(item, dict) else item for item in probe_list]\n",
    "\n",
    "# 修改all_probe_list_p1, all_probe_list_p2, all_probe_list_p2only\n",
    "all_probe_list_p1 = [convert_probe_list(probe_list) for probe_list in all_probe_list_p1]\n",
    "all_stick_list_p1 = [convert_probe_list(stick_list) for stick_list in all_stick_list_p1]\n",
    "all_probe_list_p2 = [convert_probe_list(probe_list) for probe_list in all_probe_list_p2]\n",
    "all_probe_list_p2only = [convert_probe_list(probe_list) for probe_list in all_probe_list_p2only]\n",
    "\n",
    "# 为每个列表补齐长度并转换为ndarray\n",
    "max_length1 = max(len(lst) for lst in all_probe_list_p1)\n",
    "data_visualize1 = [lst + [0] * (max_length1 - len(lst)) for lst in all_probe_list_p1]\n",
    "data_array_p1 = np.array(data_visualize1)\n",
    "\n",
    "max_length1_2 = max(len(lst) for lst in all_stick_list_p1)\n",
    "data_visualize1_2 = [lst + [0] * (max_length1_2 - len(lst)) for lst in all_stick_list_p1]\n",
    "data_array_p1_2 = np.array(data_visualize1_2)\n",
    "\n",
    "max_length2 = max(len(lst) for lst in all_probe_list_p2)\n",
    "data_visualize2 = [lst + [0] * (max_length2 - len(lst)) for lst in all_probe_list_p2]\n",
    "data_array_p2 = np.array(data_visualize2)\n",
    "\n",
    "max_length3 = max(len(lst) for lst in all_probe_list_p2only)\n",
    "data_visualize3 = [lst + [0] * (max_length3 - len(lst)) for lst in all_probe_list_p2only]\n",
    "data_array_p2only = np.array(data_visualize3)\n",
    "\n",
    "#用p2 p2only 的数据画probe frequency + p1的线条\n",
    "mean_array_p2 = np.mean(data_array_p2, axis=0)\n",
    "mean_array_p2only = np.mean(data_array_p2only, axis=0)\n",
    "mean_array_p1 = np.mean(data_array_p1,axis = 0)\n",
    "mean_array_p1_2 = np.mean(data_array_p1_2,axis = 0) #用于画p1的probe stick 图\n",
    "padded_array = np.full(50, np.nan)\n",
    "padded_array[:len(mean_array_p1)] = mean_array_p1\n",
    "\n",
    "# 计算标准误差\n",
    "def compute_standard_error(data_array):\n",
    "    n_trials = data_array.shape[1]\n",
    "    se_array = []\n",
    "    for i in range(n_trials):\n",
    "        p = np.mean(data_array[:, i])  # 成功概率\n",
    "        n = np.sum(~np.isnan(data_array[:, i]))  # 非 NaN 的样本数\n",
    "        se = np.sqrt((p * (1 - p)) / n) if n > 0 else np.nan\n",
    "        se_array.append(se)\n",
    "    return np.array(se_array)\n",
    "\n",
    "# 计算标准误差\n",
    "se_p2 = compute_standard_error(data_array_p2)\n",
    "se_p2only = compute_standard_error(data_array_p2only)\n",
    "se_p1 = compute_standard_error(data_array_p1)\n",
    "se_p1_2 = compute_standard_error(data_array_p1_2)\n",
    "se_p1_padded = np.full(50, np.nan)\n",
    "se_p1_padded[:len(se_p1)] = se_p1\n",
    "\n",
    "# 绘制p1p2p3 三个trace的频率图\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(mean_array_p2))  # 序列索引作为x轴\n",
    "plt.plot(x, mean_array_p2, label='p1p2-p2', color='blue')\n",
    "plt.fill_between(x, mean_array_p2 - se_p2, mean_array_p2 + se_p2, color='blue', alpha=0.2)#标准差\n",
    "plt.plot(x, mean_array_p2only, label='p2only', color='red')\n",
    "plt.fill_between(x, mean_array_p2only - se_p2only, mean_array_p2only + se_p2only, color='red', alpha=0.2)\n",
    "plt.plot(x, padded_array, label = 'p1p2-p1',color = 'grey')\n",
    "plt.ylim(0,1)\n",
    "plt.fill_between(\n",
    "    x, \n",
    "    np.nan_to_num(padded_array - se_p1_padded, nan=np.nan), \n",
    "    np.nan_to_num(padded_array + se_p1_padded, nan=np.nan), \n",
    "    color='grey', alpha=0.2\n",
    ")\n",
    "\n",
    "# 进行统计检验（t检验）\n",
    "u_statistic, p_value = mannwhitneyu(data_array_p2, data_array_p2only, alternative='two-sided')\n",
    "\n",
    "# 对于p值做检验：假设显著性水平为0.05\n",
    "significant_positions = np.where(p_value < 0.05)[0]\n",
    "print(f\"Positions with significant differences (p < 0.05): {significant_positions}\")\n",
    "# 标注显著性差异的点\n",
    "for pos in significant_positions[:-3]:\n",
    "    plt.text(pos, mean_array_p2[pos] + 0.05, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "for pos in significant_positions[-2:]:\n",
    "    plt.text(pos, mean_array_p2only[pos] + 0.05, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "# 设置图表标题和标签\n",
    "plt.title('Frequency of one-block probe on trial course',fontsize = 16)\n",
    "plt.xlabel('Trial number',fontsize = 14)\n",
    "plt.ylabel('One-block probe frequency',fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制p1 probe stick 两个trace的频率图\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(mean_array_p1))  # 序列索引作为x轴\n",
    "plt.plot(x, mean_array_p1, label='three-block probe', color='blue')\n",
    "plt.fill_between(x, mean_array_p1 - se_p1, mean_array_p1 + se_p1, color='blue', alpha=0.2)#标准差\n",
    "plt.plot(x, mean_array_p1_2, label='one-block probe', color='red')\n",
    "plt.fill_between(x, mean_array_p1_2 - se_p1_2, mean_array_p1_2 + se_p1_2, color='red', alpha=0.2)\n",
    "\n",
    "\n",
    "# 进行统计检验（t检验）\n",
    "u_statistic, p_value = mannwhitneyu(data_array_p1, data_array_p1_2, alternative='two-sided')\n",
    "\n",
    "# 对于p值做检验：假设显著性水平为0.05\n",
    "significant_positions = np.where(p_value < 0.05)[0]\n",
    "print(f\"Positions with significant differences (p < 0.05): {significant_positions}\")\n",
    "# 标注显著性差异的点\n",
    "for pos in significant_positions[:-7]:\n",
    "    plt.text(pos, mean_array_p1[pos] + 0.05, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "for pos in significant_positions[-6:]:\n",
    "    plt.text(pos, mean_array_p1_2[pos] + 0.05, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "# 设置图表标题和标签\n",
    "plt.title('Frequency of three/one-block probe on trial course',fontsize = 16)\n",
    "plt.xlabel('Trial number',fontsize = 14)\n",
    "plt.ylabel('Probe frequency',fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从combined_df1中用probe/stick sequence 提取相应的分数，并分别画分数的分布\n",
    "stick_score_list = []\n",
    "probe_score_list = []\n",
    "for row_idx, row in combined_df.iterrows():  \n",
    "    score_seq = row['Score_sequence']  \n",
    "    probe_seq = row['Probe_sequence']  \n",
    "    stick_seq = row['Stick_sequence']  \n",
    "\n",
    "    probe_position  = [index for index, item in enumerate(probe_seq) if isinstance(item, dict)]\n",
    "    stick_position  = [index for index, item in enumerate(stick_seq) if isinstance(item, dict)]\n",
    "    probe_score = [score_seq[i] for i in probe_position]\n",
    "    stick_score = [score_seq[i] for i in stick_position]\n",
    "    probe_score_list.extend(probe_score)\n",
    "    stick_score_list.extend(stick_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(stick_score_list, kde=True, bins=10, color='skyblue')\n",
    "plt.title(\"Score Distribution in probe trial\", fontsize=16)\n",
    "plt.xlabel(\"Score\", fontsize=15)\n",
    "plt.ylabel(\"Total counts \", fontsize=15)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe/stick fraction for 3 group\n",
    "probe_p1 = combined_df1['Probe_fraction']\n",
    "probe_p2 = combined_df2['Probe_fraction']\n",
    "probe_p2only = combined_df2only['Probe_fraction']\n",
    "stick_p1 = combined_df1['Stick_fraction']\n",
    "stick_p2 = combined_df2['Stick_fraction']\n",
    "stick_p2only = combined_df2only['Stick_fraction']\n",
    "\n",
    "#1. probe 3 group  (画stick图时切换为stick)\n",
    "group1 = stick_p1.to_numpy()\n",
    "group2 = stick_p2.to_numpy()\n",
    "group3 = stick_p2only.to_numpy()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Group\": [\"p1p2-p1\"] * len(group1) + [\"p1p2-p2\"] * len(group2) + [\"p2-only\"] * len(group3),\n",
    "    \"Value\": np.concatenate([group1, group2, group3]),\n",
    "    \"ColorGroup\": [\"p1p2-p1\"] * len(group1) + [\"p1p2-p2\"] * len(group2) + [\"p2-only\"] * len(group3)\n",
    "})\n",
    "\n",
    "# 比较组 1 和 2\n",
    "t_stat, p_value_1_2 = ttest_ind(group1, group2)\n",
    "print(f'ttest between group1 and group2: p-value = {p_value_1_2}')\n",
    "# 比较组 1 和 3\n",
    "t_stat, p_value_1_3 = ttest_ind(group1, group3)\n",
    "print(f'ttest between group1 and group3: p-value = {p_value_1_3}')\n",
    "# 比较组 2 和 3\n",
    "t_stat, p_value_2_3 = ttest_ind(group2, group3)\n",
    "print(f'ttest between group2 and group3: p-value = {p_value_2_3}')\n",
    "\n",
    "# 创建小提琴图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=\"Group\", y=\"Value\", data=df, inner=None, hue=\"ColorGroup\", palette={\"p1p2-p1\": \"#96C37D\", \"p1p2-p2\": \"#82B0D2\",\"p2-only\":\"#FA7F6F\"}, linewidth=1.5,alpha=0.3)\n",
    "sns.stripplot(x=\"Group\", y=\"Value\", data=df, jitter=True, size=5, color=\"grey\", alpha=0.6)\n",
    "\n",
    "# 计算并绘制统计信息\n",
    "for group in df[\"Group\"].unique():\n",
    "    group_values = df[df[\"Group\"] == group][\"Value\"]\n",
    "    median = np.median(group_values)\n",
    "    mean = np.mean(group_values)\n",
    "    q1 = np.percentile(group_values, 25)\n",
    "    q3 = np.percentile(group_values, 75)\n",
    "    \n",
    "    # 获取 x 坐标\n",
    "    x_pos = list(df[\"Group\"].unique()).index(group)\n",
    "    \n",
    "    # 添加统计信息到图中\n",
    "    plt.scatter(x_pos, median, color=\"red\", label=\"Median\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, mean, color=\"green\", label=\"Mean\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q1, color=\"purple\", label=\"Q1 (25th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.scatter(x_pos, q3, color=\"orange\", label=\"Q3 (75th Percentile)\" if group == df[\"Group\"].unique()[0] else \"\")\n",
    "    plt.text(x=x_pos, y=mean + 0.05, s=f\"Mean:{mean:.2f}\", color=\"darkgreen\", ha=\"center\", fontsize=12)\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.6)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.title(\"Stick fraction comparation for 3 groups\", fontsize=16)\n",
    "plt.xlabel(\"Group\", fontsize=16)\n",
    "plt.ylabel(\"Fraction\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
